# Projeto Semestral ‚Äî Classificador de Bulas de Rem√©dio (IA)

End-to-End AI Open Project ‚Äî Ci√™ncia da Computa√ß√£o ‚Äî Mackenzie ‚Äî Turma 07N ‚Äî 2025.2

## üë• Grupo
- Arthur Vignati Moscardi ‚Äî 10409688
- Enzo Bernal de Matos ‚Äî 10402685
- Ian Miranda Da Cunha ‚Äî 10409669
- Pedro Pessuto Rodrigues Ferreira ‚Äî 10409729

---

## üéØ Objetivo
Implementar um pipeline de "End-to-End AI" em Python para criar um classificador de texto. O objetivo √© treinar um modelo de linguagem (LLM) 100% aberto para identificar e classificar automaticamente se√ß√µes de bulas de rem√©dio (ex: "Posologia", "Contraindica√ß√£o", "Composi√ß√£o").

O projeto inclui as etapas de coleta de dados, etiquetagem autom√°tica, balanceamento de dataset, fine-tuning do modelo e, por fim, a cria√ß√£o de uma aplica√ß√£o web (Streamlit) para consumir o modelo treinado.

---

## ‚öôÔ∏è Pipeline do Projeto
O projeto √© dividido em um pipeline de scripts Python que preparam os dados e treinam o modelo:

1.  **Coleta de Dados:** Os arquivos `.pdf` de bulas de rem√©dio s√£o baixados do portal [Bul√°rio Eletr√¥nico da ANVISA](https://www.gov.br/anvisa/pt-br/assuntos/medicamentos/bulas) e armazenados na pasta `/data`.

2.  **Etiquetagem Autom√°tica (`2_etiquetar_automatico.py`):**
    * O script l√™ todos os PDFs da pasta `/data` usando `PyMuPDF`.
    * Utiliza Express√µes Regulares (Regex) para identificar os t√≠tulos das se√ß√µes (ex: "6. COMO DEVO USAR...").
    * Segmenta o texto da bula em blocos e atribui uma etiqueta (label) a cada bloco de texto.
    * Salva um grande dataset n√£o-balanceado (`dataset_completo_automatico.csv`).

3.  **Balanceamento (`3_balancear_dataset.py`):**
    * Analisa a distribui√ß√£o de etiquetas e identifica um desbalanceamento (excesso de "OUTROS").
    * Aplica a t√©cnica de **Undersampling**, mantendo 100% dos dados das classes importantes (ex: `POSOLOGIA`) e selecionando uma amostra aleat√≥ria de `OUTROS` de tamanho igual.
    * Salva o dataset final e balanceado (`dataset_final_balanceado.csv`).

4.  **Treinamento (`4_treinar_modelo.py`):**
    * Carrega o dataset balanceado.
    * Baixa o modelo LLM open-source **BERTimbau** (`neuralmind/bert-base-portuguese-cased`) via Hugging Face.
    * Tokeniza o texto e divide os dados em conjuntos de treino (80%) e teste (20%).
    * Executa o *fine-tuning* do modelo usando PyTorch e a biblioteca `Trainer` (com acelera√ß√£o de GPU/CUDA).

5.  **Resultado:**
    * O modelo treinado e o tokenizador s√£o salvos na pasta `/modelo_bulario_bertimbau`, prontos para serem consumidos pela aplica√ß√£o.

---

## üß∞ Tecnologias Utilizadas
- **Python 3.11 (64-bit)**: Linguagem principal do projeto.
- **PyTorch (`torch`):** O "motor" de deep learning para o treinamento via GPU.
- **Hugging Face `transformers`:** Para carregar o modelo BERTimbau e usar a API `Trainer` de fine-tuning.
- **Hugging Face `datasets`:** Para carregar e processar o dataset de forma eficiente.
- **Hugging Face `accelerate`:** Para otimizar o treino em diferentes hardwares (GPU/CPU).
- **Pandas:** Para manipula√ß√£o inicial e an√°lise dos arquivos `.csv`.
- **PyMuPDF (`fitz`):** Para a extra√ß√£o de texto de alta performance dos arquivos `.pdf`.
- **Scikit-learn (`sklearn`):** Para calcular as m√©tricas de avalia√ß√£o do modelo (Acur√°cia, F1-Score, etc.).
- **Streamlit:** (A ser implementado) Para a aplica√ß√£o web de consumo do modelo.

---

## üñ•Ô∏è Ambiente e Execu√ß√£o
O projeto exige um ambiente Python 64-bit com suporte a CUDA (GPU NVIDIA) para o treinamento.

### 1. Pr√©-requisitos
- **Python 3.11 (64-bit)** (O projeto *n√£o* √© compat√≠vel com Python 3.12+ devido √†s depend√™ncias do PyTorch).
- **NVIDIA GPU** (ex: RTX 3050) com drivers CUDA 12.1 instalados.
- **Git** (para clonar o reposit√≥rio).

### 2. Configura√ß√£o do Ambiente
```bash
# 1. Clone o reposit√≥rio
git clone <url_do_repositorio>
cd <pasta_do_projeto>

# 2. Crie o ambiente virtual (usando Python 3.11)
python -m venv .venv

# 3. Ative o ambiente
# Windows
.\.venv\Scripts\activate
# macOS/Linux
# source .venv/bin/activate

# 4. Instale o PyTorch (com suporte a GPU CUDA 12.1)
pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu121](https://download.pytorch.org/whl/cu121)

# 5. Instale o resto das depend√™ncias
pip install -r requirements.txt
```

### 3. Execu√ß√£o do Pipeline

Para gerar o dataset e treinar o modelo do zero, execute os scripts na seguinte ordem:

```bash
# 1. (Opcional) Adicione novos .pdf na pasta /data
# ...

# 2. Gera o dataset autom√°tico (dataset_completo_automatico.csv)
python 2_etiquetar_automatico.py

# 3. Balanceia o dataset (dataset_final_balanceado.csv)
python 3_balancear_dataset.py

# 4. Treina o modelo (salva em /modelo_bulario_bertimbau)
python 4_treinar_modelo.py
```

### üè∑Ô∏è Etiquetas de Classifica√ß√£o

O modelo √© treinado para classificar um trecho de texto em uma das 6 categorias:

- `INDICACAO`  Para que o rem√©dio serve.
- `COMPOSICAO`  Do que o rem√©dio √© feito.
- `CONTRAINDICACAO`  Quem n√£o deve tomar.
- `POSOLOGIA`  Como e quanto tomar.
- `EFEITOS_ADVERSOS`  Quais males pode causar.
- `OUTROS`  Qualquer texto que n√£o se encaixe nas anteriores (cabe√ßalhos, rodap√©s, se√ß√µes de advert√™ncia, etc.).
