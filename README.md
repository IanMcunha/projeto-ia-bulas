# Projeto Semestral: Classificador de Bulas de Rem√©dio (IA)

End to End AI Open Project em Python  
Curso de Ci√™ncia da Computa√ß√£o - Mackenzie - Turma 07N - 2025.2

## üë• Grupo

- Arthur Vignati Moscardi - 10409688  
- Enzo Bernal de Matos - 10402685  
- Ian Miranda Da Cunha - 10409669  
- Pedro Pessuto Rodrigues Ferreira - 10409729

##  V√≠deo

https://www.youtube.com/watch?v=bqggGWBvkuY

---

## 1. Resumo do Projeto

Este projeto implementa um pipeline completo de intelig√™ncia artificial de ponta a ponta para classificar se√ß√µes de bulas de rem√©dio.

O objetivo foi desenvolver uma solu√ß√£o 100% open source capaz de:

1. Ler bulas da ANVISA em PDF.  
2. Converter o conte√∫do em um dataset rotulado.  
3. Balancear as classes de forma controlada.  
4. Fazer fine tuning de um modelo de linguagem em portugu√™s (BERTimbau).  
5. Disponibilizar um classificador em tempo real atrav√©s de uma aplica√ß√£o web em Streamlit.

O modelo final alcan√ßou **95,1% de acur√°cia** no conjunto de teste, classificando par√°grafos em seis categorias:

- `INDICACAO`  
- `COMPOSICAO`  
- `CONTRAINDICACAO`  
- `POSOLOGIA`  
- `EFEITOS_ADVERSOS`  
- `OUTROS`

---

## 2. Objetivo Detalhado

Implementar, em Python, um pipeline de End to End AI para classificar trechos de bulas de rem√©dio em portugu√™s, usando um modelo de linguagem 100% aberto.

O pipeline inclui:

- Coleta de dados em PDF a partir do Bul√°rio Eletr√¥nico da ANVISA.  
- Extra√ß√£o e etiquetagem autom√°tica de trechos usando Regex.  
- Balanceamento de classes para evitar vi√©s em `OUTROS`.  
- Fine tuning do BERTimbau.  
- Exposi√ß√£o do modelo em uma aplica√ß√£o web acess√≠vel (Streamlit).

---

## 3. Pipeline do Projeto

O projeto √© dividido em um pipeline de scripts Python que preparam os dados e treinam o modelo.

### 3.1 Coleta de Dados

Os arquivos `.pdf` de bulas de rem√©dio s√£o baixados do portal oficial:

> Bul√°rio Eletr√¥nico da ANVISA  
> https://www.gov.br/anvisa/pt-br/assuntos/medicamentos/bulas

Esses arquivos s√£o armazenados na pasta:

```text
/data
```

Foram utilizados 78 PDFs de bulas de diferentes medicamentos (por exemplo, Dipirona, Amoxicilina, Losartana).

### 3.2 Etiquetagem Autom√°tica (`2_etiquetar_automatico.py`)

Respons√°vel por transformar PDFs n√£o estruturados em um dataset rotulado.

- L√™ todos os PDFs da pasta `/data` usando **PyMuPDF (`fitz`)**.  
- Extrai o texto de cada bula.  
- Utiliza **Express√µes Regulares (Regex)** para identificar t√≠tulos de se√ß√µes padronizadas da ANVISA  
  (por exemplo, "6. COMO DEVO USAR ESTE MEDICAMENTO").  
- Segmenta o texto em blocos e atribui uma etiqueta (label) a cada bloco.  
- Gera um dataset inicial n√£o balanceado:

```text
dataset_completo_automatico.csv
```

Esse dataset cont√©m aproximadamente 1453 exemplos.

### 3.3 Balanceamento (`3_balancear_dataset.py`)

Ao analisar o dataset bruto, foi identificado um forte desbalanceamento, com grande predomin√¢ncia de `OUTROS`.

Distribui√ß√£o aproximada:

- `OUTROS`: 893 amostras (cerca de 61,5%)  
- Demais classes (5 classes importantes): 560 amostras (cerca de 38,5%)

Treinar diretamente nesse cen√°rio geraria um modelo enviesado, tendendo a prever `OUTROS` para manter acur√°cia artificialmente alta.

Para corrigir isso, foi aplicada a t√©cnica de **undersampling**:

- Mantidas 100% das amostras das classes importantes (por exemplo, `POSOLOGIA`, `INDICACAO`, etc.).  
- Selecionada uma amostra aleat√≥ria de `OUTROS` do mesmo tamanho das demais classes combinadas.

Resultado:

```text
dataset_final_balanceado.csv   # 1120 exemplos (560 classes importantes + 560 OUTROS)
```

Esse √© o dataset final usado no treino.

### 3.4 Treinamento (`4_treinar_modelo.py`)

Script respons√°vel pelo fine tuning do modelo.

- Carrega o dataset balanceado (`dataset_final_balanceado.csv`).  
- Baixa o modelo LLM open source **BERTimbau** (`neuralmind/bert-base-portuguese-cased`) via Hugging Face.  
- Tokeniza o texto e divide os dados em:
  - 80% treino (896 exemplos)  
  - 20% teste (224 exemplos)
- Executa o fine tuning usando:
  - `transformers` (API `Trainer`)  
  - PyTorch com acelera√ß√£o GPU (CUDA)  
- Ao final, o modelo treinado e o tokenizador s√£o salvos em:

```text
/modelo_bulario_bertimbau
```

Essa pasta √© consumida diretamente pela aplica√ß√£o web.

### 3.5 Aplica√ß√£o Web (`app.py`)

Por fim, foi desenvolvida uma aplica√ß√£o em **Streamlit** para consumo do modelo:

- Carrega o modelo e o tokenizador da pasta `/modelo_bulario_bertimbau`.  
- Exp√µe uma interface em que o usu√°rio cola um par√°grafo de bula.  
- Ao clicar em ‚ÄúClassificar Texto‚Äù, o app:
  - Tokeniza o texto.  
  - Passa o batch pelo BERTimbau fine tunado.  
  - Retorna a classe prevista.

Do ponto de vista de UX:

- A interface √© organizada em duas colunas.  
- A coluna principal cont√©m:
  - T√≠tulo do app.  
  - Texto explicativo com a acur√°cia.  
  - Caixa de texto para entrada.  
  - Bot√£o de classifica√ß√£o.  
  - Card de resultado com etiqueta colorida para a classe prevista.  
- A coluna lateral cont√©m um card com efeito de glassmorphism e alguns exemplos prontos para teste.

---

## 4. Tecnologias Utilizadas

- **Python 3.11 (64 bits)**  
  Linguagem principal do projeto.

- **PyTorch (`torch`)**  
  Motor de deep learning para treino usando GPU.

- **Hugging Face `transformers`**  
  Para carregar o BERTimbau, definir o modelo de classifica√ß√£o e usar a API `Trainer`.

- **Hugging Face `datasets`**  
  Para manipula√ß√£o e divis√£o do dataset de forma eficiente.

- **Hugging Face `accelerate`**  
  Para otimizar o treino em diferentes hardwares (GPU e CPU).

- **Pandas**  
  Para manipula√ß√£o e an√°lise dos arquivos `.csv`.

- **PyMuPDF (`fitz`)**  
  Para extra√ß√£o de texto de alta performance a partir de PDFs.

- **Scikit-learn (`sklearn`)**  
  Para c√°lculo de m√©tricas de avalia√ß√£o (acur√°cia, F1 score, precis√£o, etc.).

- **Streamlit**  
  Para a aplica√ß√£o web de consumo do modelo.

---

## 5. Ambiente e Execu√ß√£o

O projeto foi pensado para treinar em GPU, mas a infer√™ncia via Streamlit roda tranquilamente em CPU.

### 5.1 Pr√©-requisitos

- **Python 3.11 (64 bits)**  
  O projeto n√£o √© compat√≠vel com Python 3.12+ devido √†s depend√™ncias atuais do PyTorch.

- **NVIDIA GPU** (por exemplo, RTX 3050) com drivers CUDA 12.1 instalados para o treino.

- **Git** para clonar o reposit√≥rio.

### 5.2 Configura√ß√£o do Ambiente

```bash
# 1. Clone o reposit√≥rio
git clone <url_do_repositorio>
cd <pasta_do_projeto>

# 2. Crie o ambiente virtual (usando Python 3.11)
python -m venv .venv

# 3. Ative o ambiente
# Windows
.\.venv\Scripts ctivate
# macOS/Linux
# source .venv/bin/activate

# 4. Instale o PyTorch (com suporte a GPU CUDA 12.1)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 5. Instale o resto das depend√™ncias
pip install -r requirements.txt
```

### 5.3 Execu√ß√£o do Pipeline

Para gerar o dataset e treinar o modelo do zero, execute os scripts na seguinte ordem:

```bash
# 1. (Opcional) Adicione novos PDFs na pasta /data
# ...

# 2. Gera o dataset autom√°tico (dataset_completo_automatico.csv)
python 2_etiquetar_automatico.py

# 3. Balanceia o dataset (dataset_final_balanceado.csv)
python 3_balancear_dataset.py

# 4. Treina o modelo (salva em /modelo_bulario_bertimbau)
python 4_treinar_modelo.py
```

---

## 6. Executando a Aplica√ß√£o Web (Streamlit)

Depois de treinar o modelo ou copiar uma vers√£o j√° treinada para a pasta `modelo_bulario_bertimbau`, basta rodar:

```bash
streamlit run app.py
```

Por padr√£o, o app fica dispon√≠vel apenas na m√°quina local.

---

## 7. Etiquetas de Classifica√ß√£o

O modelo √© treinado para classificar cada trecho de texto em uma das seis categorias abaixo:

- `INDICACAO`  
  Para que o rem√©dio serve.

- `COMPOSICAO`  
  Do que o rem√©dio √© feito.

- `CONTRAINDICACAO`  
  Quem n√£o deve tomar.

- `POSOLOGIA`  
  Como e quanto tomar.

- `EFEITOS_ADVERSOS`  
  Quais males pode causar.

- `OUTROS`  
  Qualquer texto que n√£o se encaixe nas anteriores  
  (cabe√ßalhos, rodap√©s, se√ß√µes de advert√™ncia, informa√ß√µes do fabricante, etc.).

---

## 8. Resultados e Conclus√£o

O crescimento do dataset (de um conjunto inicial pequeno para 78 bulas) e o uso de balanceamento via undersampling foram decisivos para a qualidade do modelo.

No conjunto de teste, com 224 exemplos nunca vistos durante o treino, o classificador atingiu:

- **Acur√°cia**: 95,1%  
- **F1 score (ponderado)**: 0,9517  
- **Precis√£o (ponderada)**: 0,9546  

Esses resultados mostram que:

- A estrat√©gia de etiquetagem autom√°tica baseada em Regex foi suficientemente robusta para gerar dados de treino de boa qualidade.  
- O BERTimbau se mostrou adequado para o idioma e para o tamanho do problema.  
- O pipeline completo, da coleta ao app web, comprova a viabilidade de uma solu√ß√£o de classifica√ß√£o de bulas totalmente aberta, reproduz√≠vel e extens√≠vel para trabalhos futuros.
